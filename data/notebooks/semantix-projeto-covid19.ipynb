{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listagem dos arquivos CSV que foram importados para o HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 root supergroup   62492959 2022-08-07 19:23 /user/hive/warehouse/hist_painel_covidbr/HIST_PAINEL_COVIDBR_2020_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup   76520681 2022-08-07 19:23 /user/hive/warehouse/hist_painel_covidbr/HIST_PAINEL_COVIDBR_2020_Parte2_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup   91120916 2022-08-07 19:23 /user/hive/warehouse/hist_painel_covidbr/HIST_PAINEL_COVIDBR_2021_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup    3046774 2022-08-07 19:23 /user/hive/warehouse/hist_painel_covidbr/HIST_PAINEL_COVIDBR_2021_Parte2_06jul2021.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hive/warehouse/hist_painel_covidbr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação da tabela particionada por município"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "\n",
    "schema = (\n",
    "    StructType()\n",
    "    .add('regiao', 'string')\n",
    "    .add('estado', 'string')\n",
    "    .add('municipio', 'string')\n",
    "    .add('coduf', 'integer')\n",
    "    .add('codmun', 'integer')\n",
    "    .add('codRegiaoSaude', 'integer')\n",
    "    .add('nomeRegiaoSaude', 'string')\n",
    "    .add('data', 'timestamp')\n",
    "    .add('semanaEpi', 'integer')\n",
    "    .add('populacaoTCU2019', 'integer')\n",
    "    .add('casosAcumulado', 'integer')\n",
    "    .add('casosNovos', 'integer')\n",
    "    .add('obitosAcumulado', 'integer')\n",
    "    .add('obitosNovos', 'integer')\n",
    "    .add('Recuperadosnovos', 'integer')\n",
    "    .add('emAcompanhamentoNovos', 'integer')\n",
    "    .add('interior/metropolitana', 'integer')\n",
    ")\n",
    "\n",
    "df_csv = (\n",
    "    spark.read\n",
    "    .schema(schema)\n",
    "    .option('header', True)\n",
    "    .option('encoding', 'UTF-8')\n",
    "    .option('delimiter', ';')\n",
    "    .format('csv')\n",
    "    .load('/user/hive/warehouse/hist_painel_covidbr')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- regiao: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- coduf: integer (nullable = true)\n",
      " |-- codmun: integer (nullable = true)\n",
      " |-- codRegiaoSaude: integer (nullable = true)\n",
      " |-- nomeRegiaoSaude: string (nullable = true)\n",
      " |-- data: timestamp (nullable = true)\n",
      " |-- semanaEpi: integer (nullable = true)\n",
      " |-- populacaoTCU2019: integer (nullable = true)\n",
      " |-- casosAcumulado: integer (nullable = true)\n",
      " |-- casosNovos: integer (nullable = true)\n",
      " |-- obitosAcumulado: integer (nullable = true)\n",
      " |-- obitosNovos: integer (nullable = true)\n",
      " |-- Recuperadosnovos: integer (nullable = true)\n",
      " |-- emAcompanhamentoNovos: integer (nullable = true)\n",
      " |-- interior/metropolitana: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_csv.write\n",
    " .mode(\"overwrite\")\n",
    " .partitionBy('municipio')\n",
    " .saveAsTable('painel_covidbr.hist_por_municipio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-08-08 17:16 /user/hive/warehouse/painel_covidbr.db/hist_por_municipio\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-08-08 02:48 /user/hive/warehouse/painel_covidbr.db/painel_casos_recuperados_acompanhamento\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-08-08 04:44 /user/hive/warehouse/painel_covidbr.db/sintese_casos_estados\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hive/warehouse/painel_covidbr.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura da tabela particionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "    .table('painel_covidbr.hist_por_municipio')\n",
    "    .select(\n",
    "        col('regiao'),\n",
    "        col('estado'),\n",
    "        col('municipio'),\n",
    "        col('populacaoTCU2019').alias('populacao'),\n",
    "        col('casosAcumulado'),\n",
    "        col('casosNovos'),\n",
    "        col('obitosAcumulado'),\n",
    "        col('obitosNovos'),\n",
    "        col('Recuperadosnovos').alias('recuperadosNovos'),\n",
    "        col('emAcompanhamentoNovos'),\n",
    "        col('data')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação da tabela intermediária de síntese de casos por Estados\n",
    "\n",
    "Tornou-se necessária por limitações de hardware do equipamento do autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, desc, lit, row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_regioes_estados = Window.partitionBy('regiao', 'estado').orderBy(desc('data'))\n",
    "\n",
    "df_estados = (\n",
    "    df\n",
    "    .withColumn('row', row_number().over(w_regioes_estados))\n",
    "    .filter(col('row') == 1)\n",
    "    .drop('row')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sintese_casos_estados = (\n",
    "    df_estados\n",
    "    .withColumn('incidencia', (col('casosAcumulado') / col('populacao')) * lit(100_000))\n",
    "    .withColumn('mortalidade', (col('obitosAcumulado') / col('populacao')) * lit(100_000))\n",
    "    .withColumn('letalidade', col('obitosAcumulado') / col('casosAcumulado'))\n",
    "    .select(\n",
    "        col('regiao'),\n",
    "        col('estado'),\n",
    "        col('recuperadosNovos'),\n",
    "        col('emAcompanhamentoNovos'),\n",
    "        col('casosAcumulado'),\n",
    "        col('casosNovos'),\n",
    "        col('incidencia'),\n",
    "        col('obitosAcumulado'),\n",
    "        col('obitosNovos'),\n",
    "        col('letalidade'),\n",
    "        col('mortalidade'),\n",
    "        col('populacao'),\n",
    "        col('data')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_sintese_casos_estados.write\n",
    " .mode('overwrite')\n",
    " .partitionBy('estado')\n",
    " .saveAsTable('painel_covidbr.sintese_casos_estados'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-08-08 04:44 /user/hive/warehouse/painel_covidbr.db/sintese_casos_estados/_SUCCESS\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-08-08 04:44 /user/hive/warehouse/painel_covidbr.db/sintese_casos_estados/estado=AC\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-08-08 04:44 /user/hive/warehouse/painel_covidbr.db/sintese_casos_estados/estado=AL\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-08-08 04:44 /user/hive/warehouse/painel_covidbr.db/sintese_casos_estados/estado=AM\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hive/warehouse/painel_covidbr.db/sintese_casos_estados | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Painel da COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, col, asc, desc, lit, sum, format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regioes_estados = spark.read.table('painel_covidbr.sintese_casos_estados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização do painel da COVID-19 no Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brasil = df_regioes_estados.filter(col('regiao') == 'Brasil')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Visão 1) - Casos recuperados e em acompanhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_visao1 = (\n",
    "    df_brasil\n",
    "    .select(\n",
    "        col('recuperadosNovos'),\n",
    "        col('emAcompanhamentoNovos')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+\n",
      "|recuperadosNovos|emAcompanhamentoNovos|\n",
      "+----------------+---------------------+\n",
      "|        17262646|              1065477|\n",
      "+----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_visao1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_visao1.write\n",
    " .mode('overwrite')\n",
    " .saveAsTable('painel_covidbr.painel_casos_recuperados_acompanhamento'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-08-08 02:48 /user/hive/warehouse/painel_covidbr.db/painel_casos_recuperados_acompanhamento/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        688 2022-08-08 02:48 /user/hive/warehouse/painel_covidbr.db/painel_casos_recuperados_acompanhamento/part-00000-fa4e788f-3c93-4cbc-82c9-b3da897e8991-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hive/warehouse/painel_covidbr.db/painel_casos_recuperados_acompanhamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Visão 2) - Casos confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visao2 = (\n",
    "    df_brasil\n",
    "    .select(\n",
    "        col('casosAcumulado'), \n",
    "        col('casosNovos'), \n",
    "        col('incidencia')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+\n",
      "|casosAcumulado|casosNovos|      incidencia|\n",
      "+--------------+----------+----------------+\n",
      "|      18855015|     62504|8972.29262600000|\n",
      "+--------------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_visao2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_visao2.write\n",
    " .mode('overwrite')\n",
    " .option('compression', 'snappy')\n",
    " .parquet('/user/hive/warehouse/casos_confirmados_parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-08-08 02:48 /user/hive/warehouse/casos_confirmados_parquet/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup       1010 2022-08-08 02:48 /user/hive/warehouse/casos_confirmados_parquet/part-00000-9d53944b-3b76-4529-88dd-a695d439cd89-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hive/warehouse/casos_confirmados_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Visão 3) - Óbitos confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_json, struct\n",
    "\n",
    "df_visao3 = (\n",
    "    df_brasil\n",
    "    .select(to_json(struct(\n",
    "        col('obitosAcumulado'),\n",
    "        col('obitosNovos'),\n",
    "        col('letalidade'),\n",
    "        col('mortalidade'))).alias(\"value\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                    |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|{\"obitosAcumulado\":526892,\"obitosNovos\":1780,\"letalidade\":0.02794439570,\"mortalidade\":250.72529543290204}|\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_visao3.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_visao3.write\n",
    " .format('kafka')\n",
    " .option('kafka.bootstrap.servers', 'kafka:29092')\n",
    " .option('topic', 'covid19-obitos')\n",
    " .save())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o resultado do kafka, execute:\n",
    "\n",
    "```bash\n",
    "sh scripts/teste-kafkaconsumer.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização da síntese de casos de COVID-19 no Brasil e Regiões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Visão 1) - Síntese de casos do Brasil e Regiões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sintese_regioes = (\n",
    "    df_regioes_estados\n",
    "    .groupBy('regiao')\n",
    "    .agg(\n",
    "        sum('casosAcumulado').alias('casosAcumulado'),\n",
    "        sum('obitosAcumulado').alias('obitosAcumulado'),\n",
    "        sum('populacao').alias('populacao'),\n",
    "        max('data').alias('data')\n",
    "    )\n",
    "    .withColumn('incidencia', (col('casosAcumulado') / col('populacao')) * lit(100_000))\n",
    "    .withColumn('mortalidade', (col('obitosAcumulado') / col('populacao')) * lit(100_000))\n",
    "    .select(\n",
    "        col('regiao'),\n",
    "        col('casosAcumulado'),\n",
    "        col('obitosAcumulado'),\n",
    "        col('incidencia'),\n",
    "        col('mortalidade'),\n",
    "        col('data')\n",
    "    )\n",
    "    .orderBy(desc('casosAcumulado'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+---------------+-----------------+------------------+-------------------+\n",
      "|      regiao|casosAcumulado|obitosAcumulado|       incidencia|       mortalidade|               data|\n",
      "+------------+--------------+---------------+-----------------+------------------+-------------------+\n",
      "|      Brasil|      18855015|         526892| 8972.29262594004|250.72529543290204|2021-07-06 00:00:00|\n",
      "|     Sudeste|       7138803|         245311| 8078.17951758234| 277.5908363961915|2021-07-06 00:00:00|\n",
      "|    Nordeste|       4455737|         107824| 7807.26803537182|188.92741394878797|2021-07-06 00:00:00|\n",
      "|         Sul|       3611041|          80705|12046.44691563753| 269.2321960139824|2021-07-06 00:00:00|\n",
      "|Centro-Oeste|       1916619|          49207|11760.50989275744| 301.9376361670813|2021-07-06 00:00:00|\n",
      "|       Norte|       1732815|          43845| 9401.64332010560|237.88751330640042|2021-07-06 00:00:00|\n",
      "+------------+--------------+---------------+-----------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sintese_regioes.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
